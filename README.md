# Super-Resolution CNN Project on CIFAR-10 Dataset

![Super-Resolution Example](./plots/sample-predict-and-show-triplets1.png)

## ğŸ“‹ Project Overview

This project implements a **Super-Resolution** model using Convolutional Neural Networks (CNN) to enhance image quality on the CIFAR-10 dataset. The trained model can convert low-quality images (16Ã—16 pixels) to high-quality images (32Ã—32 pixels).

### ğŸ¯ Project Goals
- Convert Low-Resolution images to High-Resolution
- Improve visual quality of images
- Preserve structure and content of original images
- Evaluate model performance using PSNR and SSIM metrics

## ğŸ—‚ Project Structure

```
Super-Resolution-CNN-CIFAR10/
â”œâ”€â”€ model/
â”‚   â””â”€â”€ best_sr_model.keras          # Final trained model
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ model_training.jpynb         # Model training notebook
â”œâ”€â”€ plots/                           # Generated plots
â”‚   â”œâ”€â”€ plot-loss-history-plots.png          # Loss history plot
â”‚   â”œâ”€â”€ visualize-hr-lr-comparison.png       # HR vs LR comparison
â”‚   â”œâ”€â”€ sample-predict-and-show-triplets1.png # Output samples
â”‚   â”œâ”€â”€ sample-predict-and-show-triplets2.png
â”‚   â”œâ”€â”€ sample-predict-and-show-triplets3.png
â”‚   â”œâ”€â”€ sample-predict-and-show-triplets4.png
â”‚   â””â”€â”€ sample-predict-and-show-triplets5.png
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ requirements.txt                 # Requirements
```

## ğŸ“Š Dataset

This project uses the **CIFAR-10** dataset which contains 60,000 32Ã—32 color images across 10 different classes.

- **High-Resolution Images (Target)**: 32Ã—32 pixels
- **Low-Resolution Images (Input)**: 16Ã—16 pixels

### Data Preprocessing
- Normalize pixel values to range [0, 1]
- Convert 32Ã—32 images to 16Ã—16 to create Low-Resolution input
- Split data into training, validation, and test sets

## ğŸ— Model Architecture

The model uses a CNN architecture with the following components:

### Main Blocks:
1. **Input**: Low-Resolution images (16Ã—16Ã—3)
2. **Feature Extraction**: Two convolutional layers with 64 filters
3. **Upsampling**: Conv2DTranspose layer for dimension increase
4. **Quality Refinement**: Two additional convolutional layers
5. **Output**: Super-Resolution image (32Ã—32Ã—3)

### Key Parameters:
- Activation function: ReLU (except output using sigmoid)
- Loss function: MSE (Mean Squared Error)
- Optimizer: Adam
- Evaluation metrics: MAE, SSIM, PSNR

## ğŸš€ Model Training

### Training Configuration:
- **Batch size**: 64
- **Epochs**: 20
- **Callbacks**:
  - Early Stopping to prevent overfitting
  - ReduceLROnPlateau for learning rate adjustment
  - ModelCheckpoint to save best model

### Training Progress:
![Loss History](./plots/plot-loss-history-plots.png)

The chart above shows the reduction of training and validation loss across different epochs.

## ğŸ“ˆ Results and Evaluation

### Evaluation Metrics:
- **PSNR (Peak Signal-to-Noise Ratio)**: Image quality metric
- **SSIM (Structural Similarity Index)**: Structural similarity metric
- **MAE (Mean Absolute Error)**: Mean absolute error

### Model Performance:
The trained model has achieved satisfactory results in enhancing image quality, with generated images being visually similar to the original High-Resolution images.

## ğŸ–¼ Output Samples

Below are samples of the model's output:

![Sample 1](./plots/sample-predict-and-show-triplets1.png)
![Sample 2](./plots/sample-predict-and-show-triplets2.png)
![Sample 3](./plots/sample-predict-and-show-triplets3.png)
![Sample 4](./plots/sample-predict-and-show-triplets4.png)
![Sample 5](./plots/sample-predict-and-show-triplets5.png)

Each sample includes three images:
- **Left**: Low-Resolution image (model input)
- **Middle**: Super-Resolution image (model output)
- **Right**: High-Resolution image (ground truth)

## ğŸ›  Setup and Usage

### Requirements:
```bash
pip install -r requirements.txt
```

### Running the Project:
1. Clone the repository
2. Install requirements
3. Run the `model_training.jpynb` notebook to train the model
4. Use the trained model for inference

### Using the Trained Model:
```python
from tensorflow.keras.models import load_model

# Load the model
model = load_model('model/best_sr_model.keras')

# Predict on new images
sr_images = model.predict(lr_images)
```

**âš ï¸ Note: If you are not using Google Colab, GPU processing settings may differ:**

- **In Google Colab**: Uses Tesla T4 or similar GPU by default
- **In local environment**: Requires manual installation of CUDA and cuDNN drivers
- **Memory settings**: You may need to reduce batch size on systems with less GPU memory

## ğŸ’¡ Key Features

- **High Performance**: Model capable of producing quality images in reasonable time
- **Simple Implementation**: Straightforward and understandable architecture
- **Comprehensive Evaluation**: Multiple metrics for quality assessment
- **Complete Documentation**: Visual samples and analytical charts provided


## ğŸ‘¨â€ğŸ’» Author
**Masoud Ghasemi**

- **GitHub**: [sorna-fast](https://github.com/sorna-fast)
- **Email**: [masudpythongit@gmail.com](mailto:masudpythongit@gmail.com)
- **linkedin**: [masoud-ghasemi](https://www.linkedin.com/in/masoud-ghasemi-748412381)
- **Telegram**: [@Masoud_Ghasemi_sorna_fast](https://t.me/Masoud_Ghasemi_sorna_fast)



## ğŸ“„ License

This project is released under the [MIT License](LICENSE).

